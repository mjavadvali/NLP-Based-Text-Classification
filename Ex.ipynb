{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mohammad Javad Valipour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from hazm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('datasets/train_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>کیفیت و حجم صدای عااااالی</td>\n",
       "      <td>این محصول توی بازار اصلاااا پیدا نمیشه من کل ت...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>شش ماه مصرف!!</td>\n",
       "      <td>دوبار از این مدل گرفتم اولاش خوبه ولی بعد از ش...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>بررسی کمی و کیفی</td>\n",
       "      <td>برای من بسیار مناسب و خریدش در شگفت انگیز حتما...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>بسته بندی ضعیف</td>\n",
       "      <td>ظاهر بامزه ای داره ولی عکسش شبیه خودش نیست جنس...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>نسبت به قیمت خوبه</td>\n",
       "      <td>خوبه نسبت به قیمت شگفت انگیزش</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      title  \\\n",
       "0   0  کیفیت و حجم صدای عااااالی   \n",
       "1   1              شش ماه مصرف!!   \n",
       "2   3           بررسی کمی و کیفی   \n",
       "3   4             بسته بندی ضعیف   \n",
       "4   6          نسبت به قیمت خوبه   \n",
       "\n",
       "                                             comment   rate  \\\n",
       "0  این محصول توی بازار اصلاااا پیدا نمیشه من کل ت...  100.0   \n",
       "1  دوبار از این مدل گرفتم اولاش خوبه ولی بعد از ش...    5.0   \n",
       "2  برای من بسیار مناسب و خریدش در شگفت انگیز حتما...    0.0   \n",
       "3  ظاهر بامزه ای داره ولی عکسش شبیه خودش نیست جنس...   60.0   \n",
       "4                      خوبه نسبت به قیمت شگفت انگیزش   45.0   \n",
       "\n",
       "   verification_status  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['comment'] = train['comment'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizer = Normalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Normalized'] = train['comment'].apply(lambda x:normalizer.normalize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagger = POSTagger(model='resources/postagger.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tagtokenized'] = train['Normalized'].apply(lambda x:tagger.tag(word_tokenize(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = Stemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemthis(tagtokenized):\n",
    "    empty = []\n",
    "    listt = tagtokenized\n",
    "    for i in range(len(listt)):\n",
    "        empty.append((stemmer.stem(listt[i][0]),listt[i][1]))\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['stemmed'] = train['tagtokenized'].apply(lambda x:stemthis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizethis(stemmed):\n",
    "    empty = []\n",
    "    listt = stemmed\n",
    "    for i in range(len(listt)):\n",
    "        if listt[i][1]=='V':\n",
    "            empty.append((lemmatizer.lemmatize(listt[i][0]),'V'))\n",
    "        else:\n",
    "            empty.append(listt[i])\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['lemmatized'] = train['stemmed'].apply(lambda x:lemmatizethis(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "listofstopwords = \"\"\"دیگران\n",
    "همچنان\n",
    "مدت\n",
    "چیز\n",
    "سایر\n",
    "جا\n",
    "طی\n",
    "کل\n",
    "کنونی\n",
    "بیرون\n",
    "مثلا\n",
    "کامل\n",
    "کاملا\n",
    "آنکه\n",
    "موارد\n",
    "واقعی\n",
    "امور\n",
    "اکنون\n",
    "بطور\n",
    "بخشی\n",
    "تحت\n",
    "چگونه\n",
    "عدم\n",
    "نوعی\n",
    "حاضر\n",
    "وضع\n",
    "مقابل\n",
    "کنار\n",
    "خویش\n",
    "نگاه\n",
    "درون\n",
    "زمانی\n",
    "بنابراین\n",
    "تو\n",
    "خیلی\n",
    "بزرگ\n",
    "خودش\n",
    "جز\n",
    "اینجا\n",
    "مختلف\n",
    "توسط\n",
    "نوع\n",
    "همچنین\n",
    "آنجا\n",
    "قبل\n",
    "جناح\n",
    "اینها\n",
    "طور\n",
    "شاید\n",
    "ایشان\n",
    "جهت\n",
    "طریق\n",
    "مانند\n",
    "پیدا\n",
    "ممکن\n",
    "کسانی\n",
    "جای\n",
    "کسی\n",
    "غیر\n",
    "بی\n",
    "قابل\n",
    "درباره\n",
    "جدید\n",
    "وقتی\n",
    "اخیر\n",
    "چرا\n",
    "بیش\n",
    "روی\n",
    "طرف\n",
    "جریان\n",
    "زیر\n",
    "آنچه\n",
    "البته\n",
    "فقط\n",
    "چیزی\n",
    "چون\n",
    "برابر\n",
    "هنوز\n",
    "بخش\n",
    "زمینه\n",
    "بین\n",
    "بدون\n",
    "استفاد\n",
    "همان\n",
    "نشان\n",
    "بسیاری\n",
    "بعد\n",
    "عمل\n",
    "روز\n",
    "اعلام\n",
    "چند\n",
    "آنان\n",
    "بلکه\n",
    "امروز\n",
    "تمام\n",
    "بیشتر\n",
    "آیا\n",
    "برخی\n",
    "علیه\n",
    "دیگری\n",
    "ویژه\n",
    "گذشته\n",
    "انجام\n",
    "حتی\n",
    "داده\n",
    "راه\n",
    "سوی\n",
    "ولی\n",
    "زمان\n",
    "حال\n",
    "تنها\n",
    "بسیار\n",
    "یعنی\n",
    "عنوان\n",
    "همین\n",
    "هبچ\n",
    "پیش\n",
    "وی\n",
    "یکی\n",
    "اینکه\n",
    "وجود\n",
    "شما\n",
    "پس\n",
    "چنین\n",
    "میان\n",
    "مورد\n",
    "چه\n",
    "اگر\n",
    "همه\n",
    "نه\n",
    "دیگر\n",
    "آنها\n",
    "باید\n",
    "هر\n",
    "او\n",
    "ما\n",
    "من\n",
    "تا\n",
    "نیز\n",
    "اما\n",
    "یک\n",
    "خود\n",
    "بر\n",
    "یا\n",
    "هم\n",
    "را\n",
    "این\n",
    "با\n",
    "آن\n",
    "برای\n",
    "و\n",
    "در\n",
    "به\n",
    "از\n",
    "که\n",
    "\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(lemmatized):\n",
    "    listt = lemmatized\n",
    "    empty = []\n",
    "    for i in range(len(listt)):\n",
    "        if listt[i][0] not in listofstopwords:\n",
    "            empty.append(listt[i])\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['removedstopwords'] = train['lemmatized'].apply(lambda x:removeStopWords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Corpus for Vectorizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeextra(removedstopwords):\n",
    "    empty = []\n",
    "    listt = removedstopwords\n",
    "    for i in range(len(listt)):\n",
    "        empty.append(listt[i][0])\n",
    "    return empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['extraremoved'] = train['removedstopwords'].apply(lambda x:removeextra(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>comment</th>\n",
       "      <th>rate</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>Normalized</th>\n",
       "      <th>tagtokenized</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>removedstopwords</th>\n",
       "      <th>extraremoved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>کیفیت و حجم صدای عااااالی</td>\n",
       "      <td>این محصول توی بازار اصلاااا پیدا نمیشه من کل ت...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>این محصول توی بازار اصلاااا پیدا نمیشه من کل ت...</td>\n",
       "      <td>[(این, DET), (محصول, N), (توی, Pe), (بازار, N)...</td>\n",
       "      <td>[(این, DET), (محصول, N), (تو, Pe), (بازار, N),...</td>\n",
       "      <td>[(این, DET), (محصول, N), (تو, Pe), (بازار, N),...</td>\n",
       "      <td>[(محصول, N), (بازار, N), (اصلاااا, N), (نمیشه,...</td>\n",
       "      <td>[محصول, بازار, اصلاااا, نمیشه, تهر, رو, گ, واق...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>شش ماه مصرف!!</td>\n",
       "      <td>دوبار از این مدل گرفتم اولاش خوبه ولی بعد از ش...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>دوبار از این مدل گرفتم اولاش خوبه ولی بعد از ش...</td>\n",
       "      <td>[(دوبار, N), (از, P), (این, DET), (مدل, N), (گ...</td>\n",
       "      <td>[(دوبار, N), (از, P), (این, DET), (مدل, N), (گ...</td>\n",
       "      <td>[(دوبار, N), (از, P), (این, DET), (مدل, N), (گ...</td>\n",
       "      <td>[(دوبار, N), (مدل, N), (گرف, V), (اولا, N), (خ...</td>\n",
       "      <td>[دوبار, مدل, گرف, اولا, خوبه, ول, ش, ماه, باد,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>بررسی کمی و کیفی</td>\n",
       "      <td>برای من بسیار مناسب و خریدش در شگفت انگیز حتما...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>برای من بسیار مناسب و خریدش در شگفت انگیز حتما...</td>\n",
       "      <td>[(برای, Pe), (من, PRO), (بسیار, ADV), (مناسب, ...</td>\n",
       "      <td>[(برا, Pe), (من, PRO), (بسیار, ADV), (مناسب, A...</td>\n",
       "      <td>[(برا, Pe), (من, PRO), (بسیار, ADV), (مناسب, A...</td>\n",
       "      <td>[(برا, Pe), (مناسب, AJ), (خرید, N), (شگف, AJ),...</td>\n",
       "      <td>[برا, مناسب, خرید, شگف, انگیز, حتما, پیشنهاد, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>بسته بندی ضعیف</td>\n",
       "      <td>ظاهر بامزه ای داره ولی عکسش شبیه خودش نیست جنس...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0</td>\n",
       "      <td>ظاهر بامزه‌ای داره ولی عکسش شبیه خودش نیست جنس...</td>\n",
       "      <td>[(ظاهر, Ne), (بامزه‌ای, AJ), (داره, V), (ولی, ...</td>\n",
       "      <td>[(ظاهر, Ne), (بامزه, AJ), (داره, V), (ول, CONJ...</td>\n",
       "      <td>[(ظاهر, Ne), (بامزه, AJ), (داره, V), (ول, CONJ...</td>\n",
       "      <td>[(ظاهر, Ne), (بامزه, AJ), (داره, V), (ول, CONJ...</td>\n",
       "      <td>[ظاهر, بامزه, داره, ول, عکس, شبیه, نیس, جنس, چ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>نسبت به قیمت خوبه</td>\n",
       "      <td>خوبه نسبت به قیمت شگفت انگیزش</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "      <td>خوبه نسبت به قیمت شگفت انگیزش</td>\n",
       "      <td>[(خوبه, V), (نسبت, N), (به, P), (قیمت, Ne), (ش...</td>\n",
       "      <td>[(خوبه, V), (نسب, N), (به, P), (قیم, Ne), (شگف...</td>\n",
       "      <td>[(خوبه, V), (نسب, N), (به, P), (قیم, Ne), (شگف...</td>\n",
       "      <td>[(خوبه, V), (نسب, N), (قیم, Ne), (شگف, AJe), (...</td>\n",
       "      <td>[خوبه, نسب, قیم, شگف, انگیز]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                      title  \\\n",
       "0   0  کیفیت و حجم صدای عااااالی   \n",
       "1   1              شش ماه مصرف!!   \n",
       "2   3           بررسی کمی و کیفی   \n",
       "3   4             بسته بندی ضعیف   \n",
       "4   6          نسبت به قیمت خوبه   \n",
       "\n",
       "                                             comment   rate  \\\n",
       "0  این محصول توی بازار اصلاااا پیدا نمیشه من کل ت...  100.0   \n",
       "1  دوبار از این مدل گرفتم اولاش خوبه ولی بعد از ش...    5.0   \n",
       "2  برای من بسیار مناسب و خریدش در شگفت انگیز حتما...    0.0   \n",
       "3  ظاهر بامزه ای داره ولی عکسش شبیه خودش نیست جنس...   60.0   \n",
       "4                      خوبه نسبت به قیمت شگفت انگیزش   45.0   \n",
       "\n",
       "   verification_status                                         Normalized  \\\n",
       "0                    0  این محصول توی بازار اصلاااا پیدا نمیشه من کل ت...   \n",
       "1                    0  دوبار از این مدل گرفتم اولاش خوبه ولی بعد از ش...   \n",
       "2                    0  برای من بسیار مناسب و خریدش در شگفت انگیز حتما...   \n",
       "3                    0  ظاهر بامزه‌ای داره ولی عکسش شبیه خودش نیست جنس...   \n",
       "4                    0                      خوبه نسبت به قیمت شگفت انگیزش   \n",
       "\n",
       "                                        tagtokenized  \\\n",
       "0  [(این, DET), (محصول, N), (توی, Pe), (بازار, N)...   \n",
       "1  [(دوبار, N), (از, P), (این, DET), (مدل, N), (گ...   \n",
       "2  [(برای, Pe), (من, PRO), (بسیار, ADV), (مناسب, ...   \n",
       "3  [(ظاهر, Ne), (بامزه‌ای, AJ), (داره, V), (ولی, ...   \n",
       "4  [(خوبه, V), (نسبت, N), (به, P), (قیمت, Ne), (ش...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [(این, DET), (محصول, N), (تو, Pe), (بازار, N),...   \n",
       "1  [(دوبار, N), (از, P), (این, DET), (مدل, N), (گ...   \n",
       "2  [(برا, Pe), (من, PRO), (بسیار, ADV), (مناسب, A...   \n",
       "3  [(ظاهر, Ne), (بامزه, AJ), (داره, V), (ول, CONJ...   \n",
       "4  [(خوبه, V), (نسب, N), (به, P), (قیم, Ne), (شگف...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  [(این, DET), (محصول, N), (تو, Pe), (بازار, N),...   \n",
       "1  [(دوبار, N), (از, P), (این, DET), (مدل, N), (گ...   \n",
       "2  [(برا, Pe), (من, PRO), (بسیار, ADV), (مناسب, A...   \n",
       "3  [(ظاهر, Ne), (بامزه, AJ), (داره, V), (ول, CONJ...   \n",
       "4  [(خوبه, V), (نسب, N), (به, P), (قیم, Ne), (شگف...   \n",
       "\n",
       "                                    removedstopwords  \\\n",
       "0  [(محصول, N), (بازار, N), (اصلاااا, N), (نمیشه,...   \n",
       "1  [(دوبار, N), (مدل, N), (گرف, V), (اولا, N), (خ...   \n",
       "2  [(برا, Pe), (مناسب, AJ), (خرید, N), (شگف, AJ),...   \n",
       "3  [(ظاهر, Ne), (بامزه, AJ), (داره, V), (ول, CONJ...   \n",
       "4  [(خوبه, V), (نسب, N), (قیم, Ne), (شگف, AJe), (...   \n",
       "\n",
       "                                        extraremoved  \n",
       "0  [محصول, بازار, اصلاااا, نمیشه, تهر, رو, گ, واق...  \n",
       "1  [دوبار, مدل, گرف, اولا, خوبه, ول, ش, ماه, باد,...  \n",
       "2  [برا, مناسب, خرید, شگف, انگیز, حتما, پیشنهاد, ...  \n",
       "3  [ظاهر, بامزه, داره, ول, عکس, شبیه, نیس, جنس, چ...  \n",
       "4                       [خوبه, نسب, قیم, شگف, انگیز]  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makecorpus(notcorpus):\n",
    "    listt = notcorpus\n",
    "    string = ''\n",
    "    for i in range(len(listt)):\n",
    "        string += listt[i]\n",
    "        if i!=len(listt):\n",
    "            string += ' '\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x_train , y_train , x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(train['extraremoved'].apply(lambda x:makecorpus(x)))\n",
    "x_train.index.name = 'id'\n",
    "x_train.columns = ['comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('datasets/train_comments.csv',index_col = 0 ,usecols=['id','verification_status'])\n",
    "x_test = pd.read_csv('datasets/test_nolabel_comments.csv',index_col=0 ,usecols=['id','comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype('int')\n",
    "x_train = x_train.fillna('0')\n",
    "x_test = x_test.fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>محصول بازار اصلاااا نمیشه تهر رو گ واقعا محصول...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>دوبار مدل گرف اولا خوبه ول ش ماه باد میکنه صدد...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>برا مناسب خرید شگف انگیز حتما پیشنهاد می‌کن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ظاهر بامزه داره ول عکس شبیه نیس جنس چوب معمول ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>خوبه نسب قیم شگف انگیز</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment\n",
       "id                                                   \n",
       "0   محصول بازار اصلاااا نمیشه تهر رو گ واقعا محصول...\n",
       "1   دوبار مدل گرف اولا خوبه ول ش ماه باد میکنه صدد...\n",
       "2        برا مناسب خرید شگف انگیز حتما پیشنهاد می‌کن \n",
       "3   ظاهر بامزه داره ول عکس شبیه نیس جنس چوب معمول ...\n",
       "4                             خوبه نسب قیم شگف انگیز "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verification_status</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    verification_status\n",
       "id                     \n",
       "0                     0\n",
       "1                     0\n",
       "3                     0\n",
       "4                     0\n",
       "6                     0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>خیلی شیک و کاربردی.\\r\\nاز بسته بندی شیک و ساده...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69180</th>\n",
       "      <td>فوق العادست حتما پیشنهاد میکنم.مطمئن باشید پشی...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130621</th>\n",
       "      <td>توی تن خوب به نظر میاد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164512</th>\n",
       "      <td>من فکر میکردم که 2تا بلندگو داشته باشه و وقتی ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105086</th>\n",
       "      <td>همه چیز این گوشی خوبه فقط دور حاشیه صفحه نمایش...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment\n",
       "id                                                       \n",
       "2267    خیلی شیک و کاربردی.\\r\\nاز بسته بندی شیک و ساده...\n",
       "69180   فوق العادست حتما پیشنهاد میکنم.مطمئن باشید پشی...\n",
       "130621                             توی تن خوب به نظر میاد\n",
       "164512  من فکر میکردم که 2تا بلندگو داشته باشه و وقتی ...\n",
       "105086  همه چیز این گوشی خوبه فقط دور حاشیه صفحه نمایش..."
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(list1,list2):\n",
    "    A = list(list1)\n",
    "    B = list(list2)\n",
    "    TPTN = 0\n",
    "    if len(A)==len(B):\n",
    "        for i in range (len(A)):\n",
    "            if A[i]==B[i]:\n",
    "                TPTN +=1\n",
    "    accuracy = TPTN / len(A)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(list1,list2):\n",
    "    A = list(list1)\n",
    "    B = list(list2)\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    if len(A)==len(B):\n",
    "        for i in range (len(A)):\n",
    "            if A[i]==B[i] and A[i]==1:\n",
    "                TP +=1\n",
    "            if A[i]==0 and B[i]==1:\n",
    "                FP +=1\n",
    "    TPFP = TP + FP\n",
    "    precision = TP/TPFP\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(list1,list2):\n",
    "    A = list(list1)\n",
    "    B = list(list2)\n",
    "    TP = 0\n",
    "    FN = 0\n",
    "    if len(A)==len(B):\n",
    "        for i in range (len(A)):\n",
    "            if A[i]==B[i] and A[i]==1:\n",
    "                TP +=1\n",
    "            if A[i]==1 and B[i]==0:\n",
    "                FN +=1\n",
    "    TPFN = TP + FN\n",
    "    recall = TP/TPFN\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(list1,list2):\n",
    "    precisiontemp = precision(list1,list2)\n",
    "    recalltemp = recall(list1,list2)\n",
    "    f1score = 2*(precisiontemp*recalltemp)/(precisiontemp+recalltemp)\n",
    "    return f1score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Vectorization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincv1 = cv1.fit_transform(x_train['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162000, 69519)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincv1.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3406637"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincv1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = TfidfVectorizer(min_df=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traincv2 = cv2.fit_transform(x_train['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162000, 69519)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincv2.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "563788.1873895341"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_traincv2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A - MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb1 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb1.fit(x_traincv1, y_train['verification_status'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testcv1 = cv1.transform(x_test['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbtest1 = mnb1.predict(x_testcv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4856"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbtest1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbtrain1 = mnb1.predict(x_traincv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21580"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbtrain1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8935679012345679"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train['verification_status'],mnbtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7252085264133457"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_train['verification_status'],mnbtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5804465544099102"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_train['verification_status'],mnbtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6448024391248816"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(y_train['verification_status'],mnbtrain1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb2 = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb2.fit(x_traincv2, y_train['verification_status'].values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_testcv2 = cv2.transform(x_test['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbtest2 = mnb2.predict(x_testcv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "558"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbtest2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnbtrain2 = mnb2.predict(x_traincv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5413"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnbtrain2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8646234567901234"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train['verification_status'],mnbtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9647145760206909"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_train['verification_status'],mnbtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19367999406572212"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_train['verification_status'],mnbtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32259459459459455"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(y_train['verification_status'],mnbtrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Count Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR1 = LogisticRegression(solver='lbfgs',multi_class='multinomial',max_iter=1000).fit(x_traincv1,y_train['verification_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtest1 = LR1.predict(x_testcv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2715"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtest1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtrain1 = LR1.predict(x_traincv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17583"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtrain1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919746913580247"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train['verification_status'],lrtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8970027867826879"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_train['verification_status'],lrtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5849714412877383"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_train['verification_status'],lrtrain1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7081378381412055"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(y_train['verification_status'],lrtrain1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- TFIDF Vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR2 = LogisticRegression(solver='lbfgs',multi_class='multinomial',max_iter=1000).fit(x_traincv2,y_train['verification_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtest2 = LR2.predict(x_testcv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1280"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtest2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtrain2 = LR2.predict(x_traincv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16652"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrtrain2.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.907283950617284"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_train['verification_status'],lrtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8585755464809032"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(y_train['verification_status'],lrtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.530264817150063"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(y_train['verification_status'],lrtrain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6556151694410051"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(y_train['verification_status'],lrtrain2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc1 = SVC(kernel = 'linear',class_weight='balanced',random_state=0).fit(x_traincv1,y_train['verification_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time kheili ziadi tool keshid va monsrf shodim vali mse qbli ha piade sazi mishe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
